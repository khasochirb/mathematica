<!DOCTYPE HTML>
<html>
<head>
    <title>Eigenvalues & Eigenvectors - International Math Hub</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="../../assets/css/first.css" />
    <link rel="stylesheet" href="../../assets/css/improvements.css" />
    <link rel="stylesheet" href="../../assets/css/topic-pages.css" />
    <style>
        /* Topic-specific overrides */
        body {
            background: var(--color-background-light) !important;
        }
        
        /* Ensure proper spacing */
        .topic-container {
            margin-top: var(--space-4);
        }
    </style>
</head>
<body class="is-preload">
    <div id="page-wrapper">
        <!-- Header -->
        <section id="header">
            <div class="header-container" style="display: flex; align-items: center; justify-content: space-between; padding: 0 5%;">
                <div class="logo">
                    <a href="../../index.html">
                        <img src="../../images/logo.png" alt="International Math Hub" style="max-height: 120px;">
                    </a>
                </div>
                                <!-- Nav -->
                <nav id="nav">
                    <ul>
                        <li><a href="../../index.html">Home</a></li>
                        <li><a href="../../features.html">Mathematics Roadmap</a></li>
                        <li><a href="../../resources.html">Resources</a></li>
                        <li><a href="../../blog.html">Blog</a></li>
                        <li><a href="../../contact.html">Contact</a></li>
                    </ul>
                </nav>
            </div>
        </section>

        <!-- Main -->
        <section id="main" class="edu-section">
            <div class="edu-container">
                <header class="text-center mb-6">
                <h2>Eigenvalues & Eigenvectors</h2>
                <p class="text-secondary">Understanding the fundamental properties and applications of eigenvalues and eigenvectors</p>
            </header>

            <div class="edu-card">
                <nav class="breadcrumb">
                    <a href="../../index.html">Home</a> &raquo;
                    <a href="../../resources.html">Resources</a> &raquo;
                    <a href="../../features.html">Mathematics Roadmap</a> &raquo;
                    <a href="../../features.html#matrices-and-determinants">Matrices and Determinants</a> &raquo;
                    <span>Eigenvalues & Eigenvectors</span>
                </nav>
            </div>

                            </div>
                <div class="topic-container">
                <div class="topic-section edu-card">
                    <h3 class="topic-header">Introduction to Eigenvalues and Eigenvectors</h3>
                    
                    <p class="text-secondary">Eigenvalues and eigenvectors are fundamental concepts in linear algebra that help us understand the behavior of linear transformations. They provide a special set of directions and scaling factors that characterize a matrix's action.</p>
                    
                    <h4>Basic Definitions</h4>
                    <p>Consider a square matrix A of size n×n. A non-zero vector v is called an <strong>eigenvector</strong> of A if there exists a scalar λ such that:</p>
                    <div class="math-formula">
                        Av = λv
                    </div>
                    <p>The scalar λ is called an <strong>eigenvalue</strong> of A corresponding to the eigenvector v.</p>
                    
                    <p>In other words, when A operates on an eigenvector, the result is a scalar multiple of that same vector. The direction of the vector remains unchanged (or exactly reversed if λ < 0), only its length is scaled by λ.</p>
                    
                    <div class="example">
                        <div class="example-title">Example: Verifying an Eigenvalue-Eigenvector Pair</div>
                        <p>Consider the matrix:</p>
                        <div class="math-formula">
                            A = [<br>
                            &nbsp;&nbsp;4&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3<br>
                            ]
                        </div>
                        <p>Let's verify that λ = 5 is an eigenvalue with corresponding eigenvector v = [2, 1].</p>
                        <div class="math-formula">
                            Av = [<br>
                            &nbsp;&nbsp;4&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3<br>
                            ] [<br>
                            &nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1<br>
                            ] = [<br>
                            &nbsp;&nbsp;4×2 + 2×1<br>
                            &nbsp;&nbsp;1×2 + 3×1<br>
                            ] = [<br>
                            &nbsp;&nbsp;10<br>
                            &nbsp;&nbsp;5<br>
                            ]
                        </div>
                        <div class="math-formula">
                            λv = 5 [<br>
                            &nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1<br>
                            ] = [<br>
                            &nbsp;&nbsp;10<br>
                            &nbsp;&nbsp;5<br>
                            ]
                        </div>
                        <p>Since Av = λv, we confirm that λ = 5 is an eigenvalue with corresponding eigenvector v = [2, 1].</p>
                    </div>
                </div>
                
                <div class="topic-section edu-card">
                    <h3 class="topic-header">Finding Eigenvalues and Eigenvectors</h3>
                    
                    <h4>The Characteristic Equation</h4>
                    <p>To find the eigenvalues of a matrix A, we need to solve the characteristic equation:</p>
                    <div class="math-formula">
                        det(A - λI) = 0
                    </div>
                    <p>where I is the identity matrix of the same size as A.</p>
                    
                    <p>The characteristic equation can be expanded to form a polynomial in λ, known as the characteristic polynomial. The roots of this polynomial are the eigenvalues of A.</p>
                    
                    <div class="example">
                        <div class="example-title">Example: Finding Eigenvalues</div>
                        <p>For the matrix:</p>
                        <div class="math-formula">
                            A = [<br>
                            &nbsp;&nbsp;4&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3<br>
                            ]
                        </div>
                        <p>We form the matrix A - λI:</p>
                        <div class="math-formula">
                            A - λI = [<br>
                            &nbsp;&nbsp;4 - λ&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3 - λ<br>
                            ]
                        </div>
                        <p>The characteristic equation is:</p>
                        <div class="math-formula">
                            det(A - λI) = 0<br>
                            (4 - λ)(3 - λ) - 2×1 = 0<br>
                            12 - 4λ - 3λ + λ² - 2 = 0<br>
                            λ² - 7λ + 10 = 0
                        </div>
                        <p>Using the quadratic formula or factoring:</p>
                        <div class="math-formula">
                            (λ - 5)(λ - 2) = 0
                        </div>
                        <p>Therefore, the eigenvalues are λ = 5 and λ = 2.</p>
                    </div>
                    
                    <h4>Finding Eigenvectors</h4>
                    <p>Once we have found an eigenvalue λ, we can find the corresponding eigenvectors by solving the homogeneous linear system:</p>
                    <div class="math-formula">
                        (A - λI)v = 0
                    </div>
                    <p>The solutions to this system form the eigenspace corresponding to λ, which is the set of all eigenvectors associated with λ, plus the zero vector.</p>
                    
                    <div class="example">
                        <div class="example-title">Example: Finding Eigenvectors</div>
                        <p>Let's find the eigenvectors for the matrix A from the previous example.</p>
                        <p>For λ = 5:</p>
                        <div class="math-formula">
                            (A - 5I)v = [<br>
                            &nbsp;&nbsp;4 - 5&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3 - 5<br>
                            ] [<br>
                            &nbsp;&nbsp;v₁<br>
                            &nbsp;&nbsp;v₂<br>
                            ] = [<br>
                            &nbsp;&nbsp;-1&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;-2<br>
                            ] [<br>
                            &nbsp;&nbsp;v₁<br>
                            &nbsp;&nbsp;v₂<br>
                            ] = [<br>
                            &nbsp;&nbsp;0<br>
                            &nbsp;&nbsp;0<br>
                            ]
                        </div>
                        <p>This gives us the system:</p>
                        <div class="math-formula">
                            -v₁ + 2v₂ = 0<br>
                            v₁ - 2v₂ = 0
                        </div>
                        <p>These equations are equivalent, giving v₁ = 2v₂. If we let v₂ = 1, then v₁ = 2, so one eigenvector is v = [2, 1].</p>
                        <p>For λ = 2:</p>
                        <div class="math-formula">
                            (A - 2I)v = [<br>
                            &nbsp;&nbsp;4 - 2&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3 - 2<br>
                            ] [<br>
                            &nbsp;&nbsp;v₁<br>
                            &nbsp;&nbsp;v₂<br>
                            ] = [<br>
                            &nbsp;&nbsp;2&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;1<br>
                            ] [<br>
                            &nbsp;&nbsp;v₁<br>
                            &nbsp;&nbsp;v₂<br>
                            ] = [<br>
                            &nbsp;&nbsp;0<br>
                            &nbsp;&nbsp;0<br>
                            ]
                        </div>
                        <p>This gives us the system:</p>
                        <div class="math-formula">
                            2v₁ + 2v₂ = 0<br>
                            v₁ + v₂ = 0
                        </div>
                        <p>These equations are equivalent, giving v₁ = -v₂. If we let v₂ = 1, then v₁ = -1, so one eigenvector is v = [-1, 1].</p>
                    </div>
                </div>
                
                <div class="topic-section edu-card">
                    <h3 class="topic-header">Properties of Eigenvalues and Eigenvectors</h3>
                    
                    <h4>Basic Properties</h4>
                    <ol>
                        <li><strong>Determinant and Trace:</strong> For an n×n matrix A:
                            <ul>
                                <li>The product of all eigenvalues equals the determinant: λ₁ × λ₂ × ... × λₙ = det(A)</li>
                                <li>The sum of all eigenvalues equals the trace: λ₁ + λ₂ + ... + λₙ = tr(A)</li>
                            </ul>
                        </li>
                        <li><strong>Algebraic and Geometric Multiplicity:</strong>
                            <ul>
                                <li>The algebraic multiplicity of an eigenvalue is its multiplicity as a root of the characteristic polynomial.</li>
                                <li>The geometric multiplicity is the dimension of the corresponding eigenspace.</li>
                                <li>The geometric multiplicity is always less than or equal to the algebraic multiplicity.</li>
                            </ul>
                        </li>
                        <li><strong>Similarity and Eigenvalues:</strong> Similar matrices have the same eigenvalues. Matrices A and B are similar if there exists an invertible matrix P such that B = P⁻¹AP.</li>
                        <li><strong>Eigenvectors of Matrix Powers:</strong> If v is an eigenvector of A with eigenvalue λ, then v is also an eigenvector of A^k with eigenvalue λ^k.</li>
                        <li><strong>Eigenvectors of Matrix Inverse:</strong> If v is an eigenvector of A with eigenvalue λ ≠ 0, then v is also an eigenvector of A⁻¹ with eigenvalue 1/λ.</li>
                        <li><strong>Eigenvectors of Transpose:</strong> The eigenvalues of A and A^T are the same, but their eigenvectors may be different.</li>
                    </ol>
                    
                    <div class="example">
                        <div class="example-title">Example: Verifying Determinant and Trace Properties</div>
                        <p>For our matrix:</p>
                        <div class="math-formula">
                            A = [<br>
                            &nbsp;&nbsp;4&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3<br>
                            ]
                        </div>
                        <p>The eigenvalues are λ₁ = 5 and λ₂ = 2.</p>
                        <p class="text-secondary">Determinant: λ₁ × λ₂ = 5 × 2 = 10</p>
                        <p>We can verify: det(A) = 4 × 3 - 2 × 1 = 12 - 2 = 10</p>
                        <p>Trace: λ₁ + λ₂ = 5 + 2 = 7</p>
                        <p>We can verify: tr(A) = 4 + 3 = 7</p>
                    </div>
                    
                    <h4>Special Cases</h4>
                    <ol>
                        <li><strong>Symmetric Matrices:</strong> If A is symmetric (A = A^T), then:
                            <ul>
                                <li>All eigenvalues are real.</li>
                                <li>Eigenvectors corresponding to different eigenvalues are orthogonal.</li>
                                <li>A can be diagonalized by an orthogonal matrix.</li>
                            </ul>
                        </li>
                        <li><strong>Hermitian Matrices:</strong> If A is Hermitian (A = A* where A* is the conjugate transpose), then:
                            <ul>
                                <li>All eigenvalues are real.</li>
                                <li>Eigenvectors corresponding to different eigenvalues are orthogonal.</li>
                            </ul>
                        </li>
                        <li><strong>Skew-Symmetric Matrices:</strong> If A is skew-symmetric (A = -A^T), then:
                            <ul>
                                <li>All eigenvalues are either 0 or pure imaginary.</li>
                            </ul>
                        </li>
                        <li><strong>Unitary Matrices:</strong> If A is unitary (AA* = I), then:
                            <ul>
                                <li>All eigenvalues have absolute value 1.</li>
                                <li>Eigenvectors corresponding to different eigenvalues are orthogonal.</li>
                            </ul>
                        </li>
                    </ol>
                </div>
                
                <div class="topic-section edu-card">
                    <h3 class="topic-header">Eigendecomposition (Diagonalization)</h3>
                    
                    <p>A key application of eigenvalues and eigenvectors is the diagonalization of matrices. A matrix A is diagonalizable if it can be written as:</p>
                    <div class="math-formula">
                        A = PDP⁻¹
                    </div>
                    <p>where D is a diagonal matrix containing the eigenvalues of A, and P is a matrix whose columns are the corresponding eigenvectors.</p>
                    
                    <h4>Conditions for Diagonalizability</h4>
                    <p>A matrix A is diagonalizable if and only if it has n linearly independent eigenvectors (where n is the size of the matrix). This happens if and only if, for each eigenvalue, the geometric multiplicity equals the algebraic multiplicity.</p>
                    
                    <div class="example">
                        <div class="example-title">Example: Diagonalization</div>
                        <p>For our matrix:</p>
                        <div class="math-formula">
                            A = [<br>
                            &nbsp;&nbsp;4&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3<br>
                            ]
                        </div>
                        <p>We found eigenvalues λ₁ = 5 and λ₂ = 2 with corresponding eigenvectors v₁ = [2, 1] and v₂ = [-1, 1].</p>
                        <p>We form the matrix P with these eigenvectors as columns:</p>
                        <div class="math-formula">
                            P = [<br>
                            &nbsp;&nbsp;2&nbsp;&nbsp;-1<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;1<br>
                            ]
                        </div>
                        <p>And the diagonal matrix D with the eigenvalues:</p>
                        <div class="math-formula">
                            D = [<br>
                            &nbsp;&nbsp;5&nbsp;&nbsp;0<br>
                            &nbsp;&nbsp;0&nbsp;&nbsp;2<br>
                            ]
                        </div>
                        <p>Now we can verify that A = PDP⁻¹:</p>
                        <p>First, find P⁻¹:</p>
                        <div class="math-formula">
                            det(P) = 2×1 - (-1)×1 = 2 + 1 = 3<br>
                            P⁻¹ = (1/3) [<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;1<br>
                            &nbsp;&nbsp;-1&nbsp;&nbsp;2<br>
                            ]
                        </div>
                        <p>Now we compute PDP⁻¹:</p>
                        <div class="math-formula">
                            PDP⁻¹ = [<br>
                            &nbsp;&nbsp;2&nbsp;&nbsp;-1<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;1<br>
                            ] [<br>
                            &nbsp;&nbsp;5&nbsp;&nbsp;0<br>
                            &nbsp;&nbsp;0&nbsp;&nbsp;2<br>
                            ] (1/3) [<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;1<br>
                            &nbsp;&nbsp;-1&nbsp;&nbsp;2<br>
                            ]
                        </div>
                        <p>Computing this product gives us:</p>
                        <div class="math-formula">
                            PDP⁻¹ = [<br>
                            &nbsp;&nbsp;4&nbsp;&nbsp;2<br>
                            &nbsp;&nbsp;1&nbsp;&nbsp;3<br>
                            ] = A
                        </div>
                        <p>Thus, we have diagonalized the matrix A.</p>
                    </div>
                    
                    <h4>Applications of Diagonalization</h4>
                    <p>Diagonalization is useful for various applications:</p>
                    <ol>
                        <li><strong>Computing Matrix Powers:</strong> If A = PDP⁻¹, then A^k = PD^kP⁻¹, which is much easier to compute since D^k simply involves raising the diagonal entries to the power k.</li>
                        <li><strong>Solving Linear Differential Equations:</strong> Diagonalization helps in solving systems of linear differential equations with constant coefficients.</li>
                        <li><strong>Analyzing Linear Transformations:</strong> Diagonalization gives insight into how a linear transformation stretches or compresses space along certain directions.</li>
                    </ol>
                </div>
                
                <div class="topic-section edu-card">
                    <h3 class="topic-header">Applications of Eigenvalues and Eigenvectors</h3>
                    
                    <h4>Principal Component Analysis (PCA)</h4>
                    <p>In PCA, a data dimensionality reduction technique, the eigenvectors of the covariance matrix represent the principal components, and the eigenvalues represent the amount of variance explained by each component.</p>
                    
                    <h4>Vibration Analysis</h4>
                    <p>In mechanical engineering, eigenvalues represent natural frequencies of vibration, and eigenvectors represent the corresponding mode shapes.</p>
                    
                    <h4>Quantum Mechanics</h4>
                    <p>In quantum mechanics, eigenvalues of certain operators represent the possible values of physical observables, and eigenvectors represent the corresponding quantum states.</p>
                    
                    <h4>Google's PageRank Algorithm</h4>
                    <p>PageRank uses the dominant eigenvector of a modified adjacency matrix of the web to rank web pages by importance.</p>
                    
                    <h4>Stability Analysis</h4>
                    <p>In dynamical systems and control theory, the eigenvalues of the system matrix determine the stability of the system. A continuous-time system is stable if all eigenvalues have negative real parts.</p>
                    
                    <div class="example">
                        <div class="example-title">Example: Application in Dynamical Systems</div>
                        <p>Consider a simple predator-prey model described by the system:</p>
                        <div class="math-formula">
                            dx/dt = ax - bxy<br>
                            dy/dt = -cy + dxy
                        </div>
                        <p>where x represents the prey population, y represents the predator population, and a, b, c, d are positive constants.</p>
                        <p>At the equilibrium point (x = c/d, y = a/b), the Jacobian matrix is:</p>
                        <div class="math-formula">
                            J = [<br>
                            &nbsp;&nbsp;0&nbsp;&nbsp;-bc/d<br>
                            &nbsp;&nbsp;ad/b&nbsp;&nbsp;0<br>
                            ]
                        </div>
                        <p>The eigenvalues of J are λ = ±i√(ac), which are pure imaginary. This indicates that the system exhibits oscillatory behavior around the equilibrium, neither growing nor decaying.</p>
                    </div>
                </div>
                
                <div class="topic-section edu-card">
                    <h3 class="topic-header">Computational Methods for Eigenvalues and Eigenvectors</h3>
                    
                    <p>For small matrices, we can find eigenvalues and eigenvectors analytically by solving the characteristic equation. However, for larger matrices, numerical methods are necessary.</p>
                    
                    <h4>Power Method</h4>
                    <p>The power method is a simple iterative algorithm for finding the dominant eigenvalue (the eigenvalue with the largest absolute value) and its corresponding eigenvector.</p>
                    <p>Steps:</p>
                    <ol>
                        <li>Start with a random non-zero vector v₀.</li>
                        <li>Iteratively compute vₖ₊₁ = Avₖ/||Avₖ|| for k = 0, 1, 2, ...</li>
                        <li>The sequence {vₖ} converges to an eigenvector corresponding to the dominant eigenvalue.</li>
                        <li>The dominant eigenvalue can be estimated as λ = v^T(Av) / v^Tv.</li>
                    </ol>
                    
                    <h4>QR Algorithm</h4>
                    <p>The QR algorithm is a more sophisticated method that can find all eigenvalues of a matrix.</p>
                    <p>Steps:</p>
                    <ol>
                        <li>Start with A₀ = A.</li>
                        <li>For k = 0, 1, 2, ..., compute the QR decomposition Aₖ = QₖRₖ.</li>
                        <li>Set Aₖ₊₁ = RₖQₖ.</li>
                        <li>The sequence {Aₖ} converges to an upper triangular matrix with the eigenvalues on the diagonal.</li>
                    </ol>
                    
                    <h4>Modern Methods</h4>
                    <p>Many modern numerical libraries use more advanced methods like the implicitly restarted Arnoldi method, the divide-and-conquer algorithm, or the multiple relatively robust representations (MRRR) algorithm for computing eigenvalues and eigenvectors efficiently and accurately.</p>
                </div>
                
                <div class="navigation">
                    <a href="linear-transformations.html" class="prev-next-btn">Previous: Linear Transformations</a>
                    <span></span> <!-- No next button since this is the last topic -->
                </div>
            </div>
        </section>

        <!-- Footer -->
        <footer id="footer">
            <div id="copyright">
                <ul class="links">
                    <li>&copy; International Math Hub</li>
                </ul>
            </div>
        </footer>
    </div>

    <!-- Scripts -->
    <script src="../../assets/js/jquery.min.js"></script>
    <script src="../../assets/js/jquery.dropotron.min.js"></script>
    <script src="../../assets/js/jquery.scrollex.min.js"></script>
    <script src="../../assets/js/browser.min.js"></script>
    <script src="../../assets/js/breakpoints.min.js"></script>
    <script src="../../assets/js/util.js"></script>
    <script src="../../assets/js/main.js"></script>
</body>
</html> 